{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T07:54:45.726746Z",
     "start_time": "2020-05-23T07:54:45.674886Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T08:03:55.688084Z",
     "start_time": "2020-05-23T08:03:55.672104Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, Input\n",
    "from keras.layers import Convolution1D, Conv1D\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, Flatten\n",
    "from keras.initializers import Constant\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from keras import Model, models\n",
    "from keras.layers import Embedding, Dense, Conv1D, GlobalMaxPooling1D, Concatenate, Dropout\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, Concatenate\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T07:54:50.184143Z",
     "start_time": "2020-05-23T07:54:48.245609Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('reviews_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T07:54:50.500124Z",
     "start_time": "2020-05-23T07:54:50.322327Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['review'], data['sentiment'], \n",
    "                                                    random_state = 42, test_size =0.05, stratify= data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T07:55:27.630937Z",
     "start_time": "2020-05-23T07:54:51.254723Z"
    }
   },
   "outputs": [],
   "source": [
    "max_features = 50000\n",
    "maxlen = 5000\n",
    "embedding_dims = 300\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features, oov_token = '<UNK>')\n",
    "\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n",
    "\n",
    "maxlen = max([len(x) for x in list_tokenized_train])\n",
    "\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "x_train = sequence.pad_sequences(list_tokenized_train, padding = 'post', \n",
    "                                 truncating = 'post', maxlen=maxlen)\n",
    "\n",
    "x_test = sequence.pad_sequences(list_tokenized_test, padding = 'post', \n",
    "                                 truncating = 'post', maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T16:11:33.311369Z",
     "start_time": "2020-05-21T16:11:33.304402Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a embedding using glove\n",
    "\n",
    "embeddings_index = dict()\n",
    "\n",
    "with open('glove.6B.300d.txt', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "        \n",
    "\n",
    "num_words = min(num_words, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, embedding_dims))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:52:21.572986Z",
     "start_time": "2020-05-22T20:52:20.865768Z"
    }
   },
   "outputs": [],
   "source": [
    "kernel_sizes=[2, 3, 4, 5, 6]\n",
    "class_num = 1\n",
    "last_activation='sigmoid' \n",
    "sequence_length = data.shape[1]\n",
    "\n",
    "batch_size = 64\n",
    "embedding_dims = 300\n",
    "epochs = 10\n",
    "max_features = num_words\n",
    "\n",
    "convs = []\n",
    "max_poolings = []\n",
    "\n",
    "\n",
    "for kernel_size in kernel_sizes:\n",
    "    convs.append(Conv1D(256, kernel_size, activation='relu'))\n",
    "    max_poolings.append(GlobalMaxPooling1D())\n",
    "\n",
    "inputs = Input(shape=(x_train.shape[1],), dtype='int32')\n",
    "\n",
    "embedding = Embedding(max_features, embedding_dims, weights=[embedding_matrix], input_length=maxlen, trainable=False)(inputs)\n",
    "\n",
    "convs2 = []\n",
    "for i in range(len(kernel_sizes)):\n",
    "    c = convs[i](embedding)\n",
    "    c = max_poolings[i](c)\n",
    "    convs2.append(c)\n",
    "x = Concatenate()(convs2)\n",
    "output = Dense(class_num, activation=last_activation)(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T17:11:08.132840Z",
     "start_time": "2020-05-21T17:10:54.333859Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T07:56:30.956442Z",
     "start_time": "2020-05-23T07:55:39.893593Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.load_model('model_textcnn_imbd.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T08:03:28.275274Z",
     "start_time": "2020-05-23T07:56:45.008110Z"
    }
   },
   "outputs": [],
   "source": [
    "result = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T08:04:06.642378Z",
     "start_time": "2020-05-23T08:04:06.430868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.93      0.92      1240\n",
      "        True       0.93      0.92      0.93      1260\n",
      "\n",
      "    accuracy                           0.92      2500\n",
      "   macro avg       0.92      0.92      0.92      2500\n",
      "weighted avg       0.92      0.92      0.92      2500\n",
      "\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1151,   89],\n",
       "       [  99, 1161]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (result > 0.5)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print('Confusion matrix:')\n",
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T08:04:16.909667Z",
     "start_time": "2020-05-23T08:04:16.863278Z"
    }
   },
   "outputs": [],
   "source": [
    "example = [\"Joaquin Phoenix gives a tour de force performance, fearless and stunning in its emotional depth and physicality. \\\n",
    "            It's impossible to talk about this without referencing Heath Ledger's Oscar-winning performance from The Dark Knight, \\\n",
    "            widely considered the definitive live-action portrayal of the Joker, so let's talk about it. \\\n",
    "            The fact is, everyone is going to be stunned by what Phoenix accomplishes, because it's what many thought impossible \\\n",
    "            a portrayal that matches and potentially exceeds that of The Dark Knight's Clown Prince of Crime\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T08:04:28.010295Z",
     "start_time": "2020-05-23T08:04:27.939486Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_example = tokenizer.texts_to_sequences(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T08:04:37.912973Z",
     "start_time": "2020-05-23T08:04:37.250793Z"
    }
   },
   "outputs": [],
   "source": [
    "example_test = sequence.pad_sequences(tokenized_example, padding = 'post', \n",
    "                                         truncating = 'post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T08:04:46.972733Z",
     "start_time": "2020-05-23T08:04:46.684796Z"
    }
   },
   "outputs": [],
   "source": [
    "example_result = model.predict(example_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T08:04:58.086449Z",
     "start_time": "2020-05-23T08:04:58.078477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9999981]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T08:06:02.300736Z",
     "start_time": "2020-05-23T08:06:02.248877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review is positive\n"
     ]
    }
   ],
   "source": [
    "if example_result > 0.5:\n",
    "    print(f'The review is positive')\n",
    "else:\n",
    "    print('The review is negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
